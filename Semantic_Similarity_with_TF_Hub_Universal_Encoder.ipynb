{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semantic Similarity with TF-Hub Universal Encoder",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "RUymE2l9GZfO"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/sriram-ramanathan/ML_L1/blob/master/Semantic_Similarity_with_TF_Hub_Universal_Encoder.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "RUymE2l9GZfO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "metadata": {
        "id": "JMyTNwSJGGWg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "co7MV6sX7Xto",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Universal Sentence Encoder\n",
        "\n",
        "Note: You can run this notebook [live in Colab](https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb) with zero setup.\n",
        "\n",
        "This notebook illustrates how to access the Universal Sentence Encoder and use it for sentence similarity and sentence classification tasks.\n",
        "\n",
        "The Universal Sentence Encoder makes getting sentence level embeddings as easy as it has historically been to lookup the embeddings for individual words. The sentence embeddings can then be trivially used to compute sentence level meaning similarity as well as to enable better performance on downstream classification tasks using less supervised training data.\n"
      ]
    },
    {
      "metadata": {
        "id": "pOTzp8O36CyQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Getting Started\n",
        "\n",
        "This section sets up the environment for access to the Universal Sentence Encoder on TF Hub and provides examples of applying the encoder to words, sentences, and paragraphs."
      ]
    },
    {
      "metadata": {
        "id": "lVjNK8shFKOC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e9d7b3ca-7a63-4c2f-f704-d43beabbc301"
      },
      "cell_type": "code",
      "source": [
        "# Install the latest Tensorflow version.\n",
        "!pip3 install --quiet \"tensorflow>=1.7\"\n",
        "# Install TF-Hub.\n",
        "!pip3 install --quiet tensorflow-hub"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "63Pd3nJnTl-i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "More detailed information about installing Tensorflow can be found at [https://www.tensorflow.org/install/](https://www.tensorflow.org/install/)."
      ]
    },
    {
      "metadata": {
        "id": "MSeY-MUQo2Ha",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "790d0dde-abd0-4068-8bf1-58aba2f6779b"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q8F4LNGFqOiq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import the Universal Sentence Encoder's TF Hub module\n",
        "embed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/1\")\n",
        "\n",
        "# Compute a representation for each message, showing various lengths supported.\n",
        "word = \"Elephant\"\n",
        "sentence = \"I am a sentence for which I would like to get its embedding.\"\n",
        "paragraph = (\n",
        "    \"Universal Sentence Encoder embeddings also support short paragraphs. \"\n",
        "    \"There is no hard limit on how long the paragraph is. Roughly, the longer \"\n",
        "    \"the more 'diluted' the embedding will be.\")\n",
        "messages = [word, sentence, paragraph]\n",
        "\n",
        "# Reduce logging output.\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "with tf.Session() as session:\n",
        "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "  message_embeddings = session.run(embed(messages))\n",
        "\n",
        "  for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
        "    print(\"Message: {}\".format(messages[i]))\n",
        "    print(\"Embedding size: {}\".format(len(message_embedding)))\n",
        "    message_embedding_snippet = \", \".join(\n",
        "        (str(x) for x in message_embedding[:3]))\n",
        "    print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BnvjATdy64eR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Semantic Textual Similarity Task Example\n",
        "\n",
        "The embeddings produced by the Universal Sentence Encoder are approximately normalized. The semantic similarity of two sentences can be trivially computed as the inner product of the encodings."
      ]
    },
    {
      "metadata": {
        "id": "h1FFCTKm7ba4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "621857f9-ed68-468d-b760-04620792b0a6"
      },
      "cell_type": "code",
      "source": [
        "def plot_similarity(labels, features, rotation):\n",
        "  corr = np.inner(features, features)\n",
        "  sns.set(font_scale=1.2)\n",
        "  g = sns.heatmap(\n",
        "      corr,\n",
        "      xticklabels=labels,\n",
        "      yticklabels=labels,\n",
        "      vmin=0,\n",
        "      vmax=1,\n",
        "      cmap=\"YlOrRd\")\n",
        "  g.set_xticklabels(labels, rotation=rotation)\n",
        "  g.set_title(\"Semantic Textual Similarity\")\n",
        "\n",
        "\n",
        "def run_and_plot(session_, input_tensor_, messages_, encoding_tensor):\n",
        "  message_embeddings_ = session_.run(\n",
        "      encoding_tensor, feed_dict={input_tensor_: messages})\n",
        "  plot_similarity(messages_, message_embeddings_, 90)\n",
        "  return message_embeddings_"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "id": "339tuJ5Pwqqv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Similarity Visualized\n",
        "Here we show the similarity in a heat map. The final graph is a 9x9 matrix where each entry `[i, j]` is colored based on the inner product of the encodings for sentence `i` and `j`."
      ]
    },
    {
      "metadata": {
        "id": "cPMCaxrZwp7t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''messages = [\n",
        "    \"phones\",\n",
        "    \"I like my phone\",\n",
        "    \"My phone is not good.\",\n",
        "    \"Your cellphone looks great.\",\n",
        "    \n",
        "\n",
        "    \"Weather\",\n",
        "    \"Will it snow tomorrow?\",\n",
        "    \"Recently a lot of hurricanes have hit the US\",\n",
        "    \"Global warming is real\",\n",
        "\n",
        "    \"Food\",\n",
        "    \"An apple a day, keeps the doctors away\",\n",
        "    \"Eating strawberries is healthy\",\n",
        "    \"Is paleo better than keto?\",\n",
        "\n",
        "    \"age\",\n",
        "    \"How old are you?\",\n",
        "    \"what is your age?\",\n",
        "]\n",
        "\n",
        "messages=[\"Ten student teams with inventions to improve people's lives worldwide - from portable ventilators for resource-strapped hospitals, to wheelchair cushions that prevent sores, to multipurpose sleeping bags for refugees - on Saturday split awards totaling $92,500 at the annual MIT IDEAS Global Challenge showcase and awards ceremony\",\n",
        " ' Grand prize winner of $15,000 went to Umbulizer, a team developing a low-cost, portable ventilator - made by modifying and simplifying the machinery - for patients in rural areas where medical resources are scarce and unreliable',\n",
        " ' \"High-end ventilators are not affordable for hospitals in Pakistan',\n",
        " 'We\\'ve basically simplified the model\" to make them less expensive, team member Moiz Imam, a senior in mechanical engineering, told MIT News',\n",
        " ' An additional nine winners, chosen by a team of judges that include seasoned entrepreneurs and venture capitalists, received four $10,000 awards and five $7,500 awards',\n",
        " ' Traditional ventilators come with about 20 different functions, which make them complex and expensive',\n",
        " 'Second-hand ventilators, which low-resource hospitals tend to buy, can run up to $15,000 to $20,000, the Umbulizer team said',\n",
        " 'The alternative is a $40 hand-operated ventilator, called an \"artificial manual breathing unit,\" or AMBU bag, which requires constant manual pumping',\n",
        " ' \"People end up getting those AMBU bags, which are dangerous for lungs because you cannot regulate the volume or the pressure,\" team member Wasay Anwer, a junior in electrical engineering and computer science at MIT, told MIT News',\n",
        " '\"That\\'s where our device comes in.\"  The Umbulizer team - including Sanchay Gupta, a Harvard Medical School student, and Hamza Khan, a Harvard Business School student - is developing an automated ventilator that keeps only four critical functions, reducing the price to around $2,000',\n",
        " '\"We talked to doctors in Pakistan and they said 90 percent of the patients only need four of the core functions of traditional second-hand ventilators',\n",
        " 'Our device provides those core functions at about 10 percent of the price,\" Gupta said',\n",
        " ' The team has a working prototype and aims to pilot the device at a major Pakistan hospital in the summer',\n",
        " '\"The [IDEAS] prize money will go a long way to helping us developing the final version of that prototype,\" Imam said',\n",
        " '\"It will also help us find local manufacturers, because our end goal is to mass manufacture this device.\"']\n",
        "'''\n",
        "\n",
        "messages=['Using a machine-learning system known as a deep neural network, MIT researchers have created thefirst model that can replicate human performance on auditory tasks such as identifying a musical genre',\n",
        " 'This model, which consists of many layers of information-processing units that can be trained on huge volumes of data to perform specific tasks, was used by the researchers to shed light on how the human brain may be performing the same tasks',\n",
        " 'What these models give us, for the first time, is machine systems that can perform sensory tasks that matter to humans and that do so at human levels, says Josh McDermott, the Frederick A',\n",
        " 'Middleton Assistant Professor of Neuroscience in the Department of Brain and Cognitive Sciences at MIT and the senior author of the study',\n",
        " 'Historically, this type of sensory processing has been difficult to understand, in part because we haven\\xe2\\x80\\x99t really had a very clear theoretical foundation and a good way to develop models of what might be going on',\n",
        "  'MIT graduate student Alexander Kell and Stanford University Assistant Professor Daniel Yamins are the paper’s lead authors.']\n",
        "similarity_input_placeholder = tf.placeholder(tf.string, shape=(None))\n",
        "similarity_message_encodings = embed(similarity_input_placeholder)\n",
        "with tf.Session() as session:\n",
        "  session.run(tf.global_variables_initializer())\n",
        "  session.run(tf.tables_initializer())\n",
        "  embeds=run_and_plot(session, similarity_input_placeholder, messages,\n",
        "               similarity_message_encodings)\n",
        "  print(embeds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b-F6ciT4R4eq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "cd0eddb6-53dc-423b-856c-258608302df5"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import pandas as pd\n",
        "def central_sentence(tvec_weights,n_cluster=2):\n",
        "    X=pd.DataFrame(tvec_weights)\n",
        "    est = KMeans(n_clusters=n_cluster)\n",
        "    Y = pd.DataFrame(est.fit_predict(X), columns=['cluster ID'])\n",
        "    Z = pd.DataFrame(est.cluster_centers_[Y['cluster ID']])\n",
        "\n",
        "    result = pd.concat([X, Y, Z], axis=1)  \n",
        "    Z.columns=[str(i)+'_Centroid' for i in  Z.columns]\n",
        "\n",
        "    #calculation distance to centroid for each sentence \n",
        "    from sklearn.metrics.pairwise import paired_distances\n",
        "    distances=paired_distances(X,Z)\n",
        "    result['distances']=distances\n",
        "    min_distance_id=list(result.groupby('cluster ID')['distances'].idxmin())\n",
        "    \n",
        "    return min_distance_id,result"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "id": "etB_zqIgSE-q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "fc582578-a481-40d5-9501-9b3354d760ca"
      },
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "min_dis,result=central_sentence(embeds,n_cluster=3)\n",
        "result['messages']=messages\n",
        "noun_cluster=find_noun_cluster(messages,result)\n",
        "\n",
        "min_dis.sort()\n",
        "summary=''\n",
        "for i in min_dis:\n",
        "  print(i,result['cluster ID'][i],messages[i])\n",
        "  \n",
        "  if result['cluster ID'][i]!=noun_cluster:\n",
        "    if summary=='':\n",
        "      summary=messages[i]\n",
        "    else:\n",
        "      summary=summary + '. ' + messages[i]\n",
        "      \n",
        "print(summary)\n",
        "  "
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using a machine-learning system known as a deep neural network, MIT researchers have created thefirst model that can replicate human performance on auditory tasks such as identifying a musical genre\n",
            "0.03333333333333333\n",
            "This model, which consists of many layers of information-processing units that can be trained on huge volumes of data to perform specific tasks, was used by the researchers to shed light on how the human brain may be performing the same tasks\n",
            "0.0\n",
            "What these models give us, for the first time, is machine systems that can perform sensory tasks that matter to humans and that do so at human levels, says Josh McDermott, the Frederick A\n",
            "0.11764705882352941\n",
            "Middleton Assistant Professor of Neuroscience in the Department of Brain and Cognitive Sciences at MIT and the senior author of the study\n",
            "0.36363636363636365\n",
            "Historically, this type of sensory processing has been difficult to understand, in part because we havenât really had a very clear theoretical foundation and a good way to develop models of what might be going on\n",
            "0.027777777777777776\n",
            "MIT graduate student Alexander Kell and Stanford University Assistant Professor Daniel Yamins are the paper’s lead authors.\n",
            "0.5294117647058824\n",
            "0 1 Using a machine-learning system known as a deep neural network, MIT researchers have created thefirst model that can replicate human performance on auditory tasks such as identifying a musical genre\n",
            "2 2 What these models give us, for the first time, is machine systems that can perform sensory tasks that matter to humans and that do so at human levels, says Josh McDermott, the Frederick A\n",
            "3 0 Middleton Assistant Professor of Neuroscience in the Department of Brain and Cognitive Sciences at MIT and the senior author of the study\n",
            "Using a machine-learning system known as a deep neural network, MIT researchers have created thefirst model that can replicate human performance on auditory tasks such as identifying a musical genre. What these models give us, for the first time, is machine systems that can perform sensory tasks that matter to humans and that do so at human levels, says Josh McDermott, the Frederick A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jNoC98srWtpi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "f91bcb31-aa28-4b08-c842-11c89830c48e"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using a machine-learning system known as a deep neural network, MIT researchers have created thefirst model that can replicate human performance on auditory tasks such as identifying a musical genre\n",
            "0.03333333333333333\n",
            "This model, which consists of many layers of information-processing units that can be trained on huge volumes of data to perform specific tasks, was used by the researchers to shed light on how the human brain may be performing the same tasks\n",
            "0.0\n",
            "What these models give us, for the first time, is machine systems that can perform sensory tasks that matter to humans and that do so at human levels, says Josh McDermott, the Frederick A\n",
            "0.11764705882352941\n",
            "Middleton Assistant Professor of Neuroscience in the Department of Brain and Cognitive Sciences at MIT and the senior author of the study\n",
            "0.36363636363636365\n",
            "Historically, this type of sensory processing has been difficult to understand, in part because we havenât really had a very clear theoretical foundation and a good way to develop models of what might be going on\n",
            "0.027777777777777776\n",
            "MIT graduate student Alexander Kell and Stanford University Assistant Professor Daniel Yamins are the paper’s lead authors.\n",
            "0.5294117647058824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9qYPU67kXBuU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0bef670-0254-4bbe-fdd6-3badbbf6fff1"
      },
      "cell_type": "code",
      "source": [
        "noun_cluster"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "metadata": {
        "id": "Y-MpkVGwlHVR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c4c5c19f-47d1-4a5c-b2db-1f5506abfd1f"
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"averaged_perceptron_tagger\")\n",
        "from nltk.tag import pos_tag"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /content/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "0V3WQgCAkxYV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "07216239-ea86-4fb2-fc05-af0f383c75af"
      },
      "cell_type": "code",
      "source": [
        "#finding noun cluster \n",
        "def find_noun_cluster(messages,result):\n",
        "  noun_perc=[]\n",
        "  for i in range(len(messages)):\n",
        "    sentence = messages[i]\n",
        "    tagged_sent = pos_tag(sentence.split())\n",
        "    \n",
        "\n",
        "    propernouns = [word for word,pos in tagged_sent if pos == 'NNP']\n",
        "    print(sentence)\n",
        "    nperc=(len(propernouns)/len(sentence.split()))\n",
        "    noun_perc.append(nperc)\n",
        "    print(nperc)\n",
        "\n",
        "  result['noun_perc']=noun_perc\n",
        "  cluster_noun_perc=result.groupby('cluster ID')['noun_perc'].agg('mean')\n",
        "  return cluster_noun_perc.idxmax()"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JHrYc6ENWhGN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "001a0502-050f-446f-8416-4eb8f51ab9fe"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using a machine-learning system known as a deep neural network, MIT researchers have created thefirst model that can replicate human performance on auditory tasks such as identifying a musical genre\n",
            "0.03333333333333333\n",
            "This model, which consists of many layers of information-processing units that can be trained on huge volumes of data to perform specific tasks, was used by the researchers to shed light on how the human brain may be performing the same tasks\n",
            "0.0\n",
            "What these models give us, for the first time, is machine systems that can perform sensory tasks that matter to humans and that do so at human levels, says Josh McDermott, the Frederick A\n",
            "0.11764705882352941\n",
            "Middleton Assistant Professor of Neuroscience in the Department of Brain and Cognitive Sciences at MIT and the senior author of the study\n",
            "0.36363636363636365\n",
            "Historically, this type of sensory processing has been difficult to understand, in part because we havenât really had a very clear theoretical foundation and a good way to develop models of what might be going on\n",
            "0.027777777777777776\n",
            "MIT graduate student Alexander Kell and Stanford University Assistant Professor Daniel Yamins are the paper’s lead authors.\n",
            "0.5294117647058824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "_aZ22_gZVXsG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "a77c2ef4-b834-46d2-bffe-bba801542192"
      },
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "def find_silhouette_score(tvec_weights):\n",
        "    ss=[]\n",
        "    nc=[]\n",
        "    for n in range(2,int(len(tvec_weights)/4)):\n",
        "        sentences_id,result=central_sentence(tvec_weights,n)\n",
        "        ss.append(metrics.silhouette_score(tvec_weights,result['cluster ID'], metric='euclidean'))\n",
        "        nc.append(n)\n",
        "    zipped=find_silhouette_score(tvec_weights)\n",
        "    zipped.sort(key = lambda t: t[1],reverse=True)\n",
        "    optimal_k=zipped[0][0]\n",
        "    \n",
        "    return zip(nc,ss),optima\n",
        "  \n",
        "zipped,opti=find_silhouette_score(embeds)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NKchefJ1SotA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "069bdf6d-a7fd-49be-f83f-153ce6cf1d43"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6FjdeCqPJeg-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluation: STS (Semantic Textual Similarity) Benchmark\n",
        "\n",
        "The [**STS Benchmark**](http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark) provides an intristic evaluation of the degree to which similarity scores computed using sentence embeddings align with human judgements. The benchmark requires systems to return similarity scores for a diverse selection of sentence pairs. [Pearson correlation](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) is then used to evaluate the quality of the machine similarity scores against human judgements."
      ]
    },
    {
      "metadata": {
        "id": "q5nuBbI1iFQR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Download data"
      ]
    },
    {
      "metadata": {
        "id": "VOs8ZfOnJeBF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "import scipy\n",
        "import math\n",
        "\n",
        "\n",
        "def load_sts_dataset(filename):\n",
        "  # Loads a subset of the STS dataset into a DataFrame. In particular both\n",
        "  # sentences and their human rated similarity score.\n",
        "  sent_pairs = []\n",
        "  with tf.gfile.GFile(filename, \"r\") as f:\n",
        "    for line in f:\n",
        "      ts = line.strip().split(\"\\t\")\n",
        "      # (sent_1, sent_2, similarity_score)\n",
        "      sent_pairs.append((ts[5], ts[6], float(ts[4])))\n",
        "  return pandas.DataFrame(sent_pairs, columns=[\"sent_1\", \"sent_2\", \"sim\"])\n",
        "\n",
        "\n",
        "def download_and_load_sts_data():\n",
        "  sts_dataset = tf.keras.utils.get_file(\n",
        "      fname=\"Stsbenchmark.tar.gz\",\n",
        "      origin=\"http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\",\n",
        "      extract=True)\n",
        "\n",
        "  sts_dev = load_sts_dataset(\n",
        "      os.path.join(os.path.dirname(sts_dataset), \"stsbenchmark\", \"sts-dev.csv\"))\n",
        "  sts_test = load_sts_dataset(\n",
        "      os.path.join(\n",
        "          os.path.dirname(sts_dataset), \"stsbenchmark\", \"sts-test.csv\"))\n",
        "\n",
        "  return sts_dev, sts_test\n",
        "\n",
        "\n",
        "sts_dev, sts_test = download_and_load_sts_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MkqPOxH3EL1j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Build Evaluation Graph"
      ]
    },
    {
      "metadata": {
        "id": "PeoO8z30smCS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text_a = sts_dev['sent_1'].tolist()\n",
        "text_b = sts_dev['sent_2'].tolist()\n",
        "dev_scores = sts_dev['sim'].tolist()\n",
        "sts_input1 = tf.placeholder(tf.string, shape=(None))\n",
        "sts_input2 = tf.placeholder(tf.string, shape=(None))\n",
        "\n",
        "# For evaluation we use exactly normalized rather than\n",
        "# approximately normalized.\n",
        "sts_encode1 = tf.nn.l2_normalize(embed(sts_input1))\n",
        "sts_encode2 = tf.nn.l2_normalize(embed(sts_input2))\n",
        "sim_scores = tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8OKy8WhnKRe_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate Sentence Embeddings"
      ]
    },
    {
      "metadata": {
        "id": "W-q2r7jyZGb7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_sts_benchmark(session):\n",
        "  \"\"\"Returns the similarity scores\"\"\"\n",
        "  emba, embb, scores = session.run(\n",
        "      [sts_encode1, sts_encode2, sim_scores],\n",
        "      feed_dict={\n",
        "          sts_input1: text_a,\n",
        "          sts_input2: text_b\n",
        "      })\n",
        "  return scores\n",
        "\n",
        "\n",
        "with tf.Session() as session:\n",
        "  session.run(tf.global_variables_initializer())\n",
        "  session.run(tf.tables_initializer())\n",
        "  scores = run_sts_benchmark(session)\n",
        "\n",
        "pearson_correlation = scipy.stats.pearsonr(scores, dev_scores)\n",
        "print('Pearson correlation coefficient = {0}\\np-value = {1}'.format(\n",
        "    pearson_correlation[0], pearson_correlation[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}